# 这是我工作的内容，每天都能学到东西 #
_目前刚到公司，主要任务是学习_
### 2015-09-14 ###
1. pyenv和virtualenv的学习和安装
2. celery和celery flower的安装和简单使用
3. redis的简单使用
4. 开周会听同事对项目的理解和对互联网的理解，以及各自学习的方法，学到很多
5. 在查找资料的过程中碰到两个很好的博客，向他们学习
   [竹子-博客](http://www.cnblogs.com/peida/) [阿小信大人](http://note.axiaoxin.com/index.html)

### 2015-09-15 ###
1. Laravel下的数据库迁移和Test （**未完全看完**）
2. 阅读datartery的项目文档，并提了几个问题
3. Scrapy[0.24中文版](https://scrapy-chs.readthedocs.org/zh_CN/0.24/)        [1.0英文版](http://doc.scrapy.org/en/1.0/index.html) (应该看英文版，中文只是参照)的安装和学习
4. Xpath的学习
5. 阅读datartery的crawler代码

### 2015-09-16 ###
1. 阅读datartery的web和annlysis (_前半部分_)代码
2. python collections库的学习
3. jieba分词的学习

### 2015-09-17 ###
1. [laravel debugbar](https://github.com/barryvdh/laravel-debugbar)[_(文档)_](http://phpdebugbar.com/docs/)插件学习
2. 关联规则学习(pymining)
3. 阅读datartery的annlysis (_后半部分_)代码



### 2015-09-18 ###
1. python和json转换（python json库使用，如ujson，anyjson）
2. 整理笔记
3. 阅读roclaws的文档和代码
4. 继续学习scrapy

***

### 2015-09-21 ###
1. 使用 lv 5.1.11 重建 web 目录结构（重构web项目，因为lv版本更新，抓取用户指定页面后保存，用到Spider，CrolSipder，）
2. 写相关项目测试（从最简单的路由测试起）
3. 问题：
   1. 抓取内容如何展现(数据本身也是一个页面)
   2. 用户在不懂得规则的情况下如何使用
   3. user -> project -> spider -> job -> data
   4. [phantomjs](http://phantomjs.org/quick-start.html)
   5. [pyspider 爬虫教程（三）：使用 PhantomJS 渲染带 JS 的页面](http://segmentfault.com/a/1190000002477913)
   6. [使用Scrapy抓取数据](http://segmentfault.com/a/1190000000583419)
   7. follow_pattern，save_pattern都是一个数组
4. 内容：
   1. 创建一个seed用户
   2. 用户登录，注册
   3. debugger 插件

## TODO ##
1. github网站用法（Weki（目的：方便记录我们自己的项目知识））
2. git stash && git flower(结合sourcetree)
